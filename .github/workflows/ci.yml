name: CI - Tests and Linting

on:
  push:                        # DÃ©clenche sur push
    branches: [ main, feature/testsinglefonction ] # Branches surveillÃ©es
  pull_request:                # DÃ©clenche sur PR
    branches: [ main ]

jobs:
  tests:
    runs-on: ubuntu-latest     # Machine GitHub (Ubuntu)
    strategy:
      matrix:
        python-version: ["3.10", "3.11"]  # Teste plusieurs versions de Python

    steps:
      # 1) RÃ©cupÃ©ration du code
      - name: ğŸšš Checkout repository
        uses: actions/checkout@v4        # Clone le repo dans le runner

      # 2) Python
      - name: ğŸ Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5    # Installe la version de Python demandÃ©e
        with:
          python-version: ${{ matrix.python-version }}

      # 3) Java (requis par Spark)
      - name: â˜• Set up Java 11 (required by Spark)
        uses: actions/setup-java@v4      # Installe Java
        with:
          distribution: temurin          # Distribution OpenJDK
          java-version: "11"             # Version compatible Spark 3.5.x

      # 4) Poetry
      - name: ğŸ“¦ Install Poetry
        uses: abatilo/actions-poetry@v3  # Installe Poetry
        with:
          poetry-version: "1.8.3"        # Version stable de Poetry

      - name: ğŸ§­ Configure Poetry virtualenv
        run: |
          poetry config virtualenvs.create true         # Active l'env virtuel Poetry
          poetry config virtualenvs.in-project true     # Met l'env dans .venv du repo

      # 5) Cache (accÃ©lÃ¨re les builds)
      - name: ğŸ§  Cache Poetry and venv
        uses: actions/cache@v4
        with:
          path: |                                      # Dossiers Ã  mettre en cache
            .venv
            ~/.cache/pypoetry
          key: ${{ runner.os }}-poetry-${{ hashFiles('**/poetry.lock') }} # ClÃ© unique par lockfile
          restore-keys: |
            ${{ runner.os }}-poetry-                   # Fallback si la clÃ© exacte n'existe pas

      # 6) Installation des dÃ©pendances
      - name: ğŸ› ï¸ Install dependencies
        run: poetry install --no-interaction           # Installe deps (prod + dev)

      # 7) Lint/format (optionnel : ne casse pas la CI si vous dÃ©butez)
      # 7) Lint & format checks (avec Ruff au lieu de Black + isort)
      - name: ğŸ” Run Ruff checks
        run: |
          poetry run ruff check .           # VÃ©rifie lint + imports + style
          poetry run ruff format --check .  # VÃ©rifie formatage type Black
          poetry run ruff check --fix .   # (Optionnel) Corrige automatiquement


      # 8) Tests unitaires (avec jolis groupes)
      - name: ğŸ§ª Run unit tests (all)
        env:
          PYSPARK_PYTHON: ${{ github.workspace }}/.venv/bin/python  # Force PySpark Ã  utiliser l'env Poetry
        run: |
          # Lancement global (coverage sur le package)
          poetry run pytest --cov=spark_prepkit -q

      # 9) (Optionnel) Exemples de tests ciblÃ©s (sÃ©parateurs visuels)
      - name: ğŸ§ª trim_strings
        if: always()                               # Toujours exÃ©cuter pour afficher les sections
        run: poetry run pytest -q tests/test_trim_strings.py

      - name: ğŸ§ª normalize_yes_no
        if: always()
        run: poetry run pytest -q tests/test_normalize_yes_no.py

      - name: ğŸ§ª cast_numerics
        if: always()
        run: poetry run pytest -q tests/test_cast_numerics.py

      - name: ğŸ§ª add_bmi
        if: always()
        run: poetry run pytest -q tests/test_add_bmi.py
